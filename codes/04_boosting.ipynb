{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50d1dc35-8ddb-4f09-9bc0-a7df11313c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_and_import(package, import_name=None):\n",
    "    \"\"\"\n",
    "    Try to import a package. If it's not installed, install it via pip and import again.\n",
    "    package: name on pip (e.g. 'pandas')\n",
    "    import_name: name used in import (e.g. 'pandas' or 'matplotlib.pyplot').\n",
    "                 If None, uses package.\n",
    "    \"\"\"\n",
    "    if import_name is None:\n",
    "        import_name = package\n",
    "\n",
    "    try:\n",
    "        return importlib.import_module(import_name)\n",
    "    except ImportError:\n",
    "        print(f\"{import_name} not found, installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        return importlib.import_module(import_name)\n",
    "\n",
    "# use it for your libs\n",
    "pd = install_and_import(\"pandas\")\n",
    "np = install_and_import(\"numpy\")\n",
    "plt = install_and_import(\"matplotlib.pyplot\", \"matplotlib.pyplot\")\n",
    "# Use the function to install xgboost instead of direct pip command\n",
    "xgb = install_and_import(\"xgboost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "483b1ddd-20ef-484a-88ee-a5520c6b031f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   site_id_(telephely)  class_size  math_score_8_std mother_education_level  \\\n",
      "0              3512501          26          1.367778  apprenticeship_school   \n",
      "1              3338601          22         -0.700054  secondary_with_matura   \n",
      "2              3352101          17         -2.378011      less_than_primary   \n",
      "3              2911501          22         -1.596259      less_than_primary   \n",
      "4              3772301          19          0.777019  secondary_with_matura   \n",
      "\n",
      "  father_education_level books_at_home  family_background_index_std  \\\n",
      "0                college     up_to_300                     0.318596   \n",
      "1  secondary_with_matura       300_600                     0.536068   \n",
      "2         primary_school          0_50                    -2.399800   \n",
      "3      less_than_primary     around_50                    -2.182328   \n",
      "4  secondary_with_matura     up_to_150                     0.698790   \n",
      "\n",
      "  student_gender class_curriculum_type multiplied_disadvantaged  \\\n",
      "0           girl                normal                       no   \n",
      "1           girl                normal                       no   \n",
      "2            boy                normal                      yes   \n",
      "3           girl                normal                       no   \n",
      "4            boy                normal                       no   \n",
      "\n",
      "   county_code_school settlement_type_school maintainer_type_group_school  \\\n",
      "0                   1               Budapest     central_government_state   \n",
      "1                  15                   town     central_government_state   \n",
      "2                  15      village_2000_5000     central_government_state   \n",
      "3                   5                   town     central_government_state   \n",
      "4                  13                   town     central_government_state   \n",
      "\n",
      "   student_teacher_ratio  \n",
      "0              11.681592  \n",
      "1              10.349515  \n",
      "2              12.652174  \n",
      "3               7.952941  \n",
      "4              11.782051  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filtered_df_anal = pd.read_csv(r\"C:\\Users\\User\\Downloads\\filtered_data_anal(2).csv\")\n",
    "\n",
    "# első pár sor ellenőrzéshez:\n",
    "print(filtered_df_anal.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31a2f7c3-836a-4f64-828f-b4fe970f4077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best hyperparameters: {'subsample': 1.0, 'reg_lambda': 0, 'reg_alpha': 0.75, 'n_estimators': 700, 'max_depth': 4, 'learning_rate': 0.15, 'colsample_bytree': 0.8}\n",
      "RMSE: 0.7925342808887187\n",
      "R^2: 0.3203128901262986\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd                         # Data manipulation\n",
    "import numpy as np                          # Numerical operations\n",
    "from xgboost import XGBRegressor            # XGBoost regression model\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Define target and features\n",
    "# -----------------------------\n",
    "target = \"math_score_8_std\"                 # Target variable to predict\n",
    "\n",
    "# Build list of columns to drop safely (only those that exist in the DataFrame)\n",
    "cols_to_drop = [target] \n",
    "cols_to_drop = [c for c in cols_to_drop if c in filtered_df_anal.columns]\n",
    "\n",
    "# Feature matrix X and target vector y\n",
    "# Feature matrix X and target vector y\n",
    "X = filtered_df_anal.drop(columns=cols_to_drop).copy()   # All predictors\n",
    "y = filtered_df_anal[target].copy()                      # Outcome\n",
    "\n",
    "# ------------------------------------\n",
    "# 2. Handle categorical (object) data\n",
    "# ------------------------------------\n",
    "# XGBoost needs numeric or pandas 'category' dtypes\n",
    "cat_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "X[cat_cols] = X[cat_cols].astype(\"category\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Train–test split (80–20)\n",
    "# -----------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=76678\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Base XGBoost model\n",
    "# -----------------------------\n",
    "base_model = XGBRegressor(\n",
    "    objective=\"reg:squarederror\",  # Explicit regression objective\n",
    "    tree_method=\"hist\",            # Required for categorical support / efficiency\n",
    "    enable_categorical=True,       # Tell XGBoost that we use categorical features\n",
    "    random_state=76678,\n",
    ")\n",
    "\n",
    "# --------------------------------------------\n",
    "# 5. Hyperparameter search space (Randomized)\n",
    "# --------------------------------------------\n",
    "param_distributions = {\n",
    "    \"n_estimators\": [100, 200, 300, 500, 700],\n",
    "    \"learning_rate\": [0.01, 0.03, 0.05, 0.1, 0.15, 0.2],\n",
    "    \"max_depth\": [3, 4, 5, 6, 7, 8, 10],\n",
    "    \"subsample\": [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"reg_lambda\": [0, 1, 2, 5, 10],             # L2 regularization\n",
    "    \"reg_alpha\": [0, 0.1, 0.25, 0.5, 0.75, 1],  # L1 regularization\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=base_model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=30,                         # Number of sampled hyperparameter combinations\n",
    "    scoring=\"neg_root_mean_squared_error\",  # Minimize RMSE\n",
    "    cv=5,                              # 5-fold cross-validation\n",
    "    verbose=1,\n",
    "    n_jobs=-1,                         # Use all available cores\n",
    "    random_state=76678,\n",
    ")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 6. Fit hyperparameter search & evaluate model\n",
    "# ---------------------------------------------\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model after tuning\n",
    "model = random_search.best_estimator_\n",
    "\n",
    "print(\"Best hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Predictions on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Regression metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R^2:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d634223-57df-48e3-9048-2be4f28bca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from xgboost import plot_importance\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Global plotting style for publication-quality figures\n",
    "# -------------------------------------------------------------------\n",
    "mpl.rcParams.update({\n",
    "    \"font.family\": \"Times New Roman\",\n",
    "    \"font.size\": 11,\n",
    "    \"axes.titlesize\": 13,\n",
    "    \"axes.labelsize\": 12,\n",
    "    \"xtick.labelsize\": 10,\n",
    "    \"ytick.labelsize\": 10,\n",
    "    \"axes.spines.top\": False,\n",
    "    \"axes.spines.right\": False,\n",
    "    \"figure.dpi\": 600,\n",
    "})\n",
    "\n",
    "save_dir = r\"C:\\Users\\User\\Desktop\\Figures\\Figures\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1. True vs. predicted values\n",
    "# -------------------------------------------------------------------\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "ax.scatter(y_test, y_pred, s=20, alpha=0.6)\n",
    "ax.set_xlabel(\"True $math\\\\_score\\\\_8\\\\_std$\")\n",
    "ax.set_ylabel(\"Predicted $math\\\\_score\\\\_8\\\\_std$\")\n",
    "ax.set_title(\"True vs. predicted values\")\n",
    "\n",
    "min_val = min(y_test.min(), y_pred.min())\n",
    "max_val = max(y_test.max(), y_pred.max())\n",
    "ax.plot([min_val, max_val], [min_val, max_val],\n",
    "        linestyle=\"--\", linewidth=1)\n",
    "\n",
    "ax.set_xlim(min_val, max_val)\n",
    "ax.set_ylim(min_val, max_val)\n",
    "\n",
    "ax.grid(True, linestyle=\":\", linewidth=0.5, alpha=0.7)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(save_dir, \"true_vs_predicted.png\"), dpi=600)\n",
    "plt.close(fig)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2. Residuals histogram\n",
    "# -------------------------------------------------------------------\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "ax.hist(residuals, bins=30, edgecolor=\"black\", alpha=0.8)\n",
    "ax.set_xlabel(\"Residual (true – predicted)\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.set_title(\"Distribution of residuals\")\n",
    "\n",
    "ax.axvline(0, linestyle=\"--\", linewidth=1)\n",
    "\n",
    "ax.grid(True, linestyle=\":\", linewidth=0.5, alpha=0.7)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(save_dir, \"residuals_histogram.png\"), dpi=600)\n",
    "plt.close(fig)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3. Residuals vs. fitted values\n",
    "# -------------------------------------------------------------------\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "ax.scatter(y_pred, residuals, s=20, alpha=0.6)\n",
    "ax.axhline(0, linestyle=\"--\", linewidth=1)\n",
    "\n",
    "ax.set_xlabel(\"Predicted $math\\\\_score\\\\_8\\\\_std$\")\n",
    "ax.set_ylabel(\"Residual (true – predicted)\")\n",
    "ax.set_title(\"Residuals vs. predicted values\")\n",
    "\n",
    "ax.grid(True, linestyle=\":\", linewidth=0.5, alpha=0.7)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(save_dir, \"residuals_vs_fitted.png\"), dpi=600)\n",
    "plt.close(fig)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 4. Feature importance (XGBoost)\n",
    "# -------------------------------------------------------------------\n",
    "fig, ax = plt.subplots(figsize=(7, 9))\n",
    "\n",
    "plot_importance(\n",
    "    model,\n",
    "    max_num_features=20,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "ax.set_title(\"Top 20 feature importances (XGBoost)\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(save_dir, \"feature_importance.png\"), dpi=600)\n",
    "plt.close(fig)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
